{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 2: Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración de la GPU\n",
    "\n",
    "Por un motivo que se desconoce, cuando se utiliza el acelerador P100, es necesario limitar el crecimiento de la GPU (para más detalles, revisar [acá](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth)). Otro punto es que esta celda debe venir antes de cualquier importación ya que internamente modifican la capacidad de la GPU (ver el siguiente [hilo](https://github.com/hunglc007/tensorflow-yolov4-tflite/issues/171)), y por ende, obtenemos el error `Physical devices cannot be modified after being initialized`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.config import list_physical_devices\n",
    "from tensorflow.config.experimental import set_memory_growth\n",
    "\n",
    "gpus = list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(\"error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalación de dependencias\n",
    "\n",
    "Utilizaremos las siguientes librerías:\n",
    "\n",
    "- `dotwiz`: Permite acceder a los diccionarios en Python con una notación de tipo \"punto\" (exactamente como se hace en Javascript).\n",
    "- `gdown`: Permite descargar archivos desde Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install dotwiz gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería Hugging Face genera unas advertencias que no aplican en nuestros desarrollos, por lo que se silencian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización de constantes\n",
    "\n",
    "Definiremos al objeto `CONSTANTS` que contendrá todas las constantes a utilizar organizadas de forma jerárquica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotwiz import DotWiz\n",
    "from re import compile\n",
    "from math import log, floor\n",
    "from logging import info\n",
    "\n",
    "CONSTANTS = DotWiz({\n",
    "    \"DATASETS\": {\n",
    "        \"PAN\": {\n",
    "            \"PATHS\": {\n",
    "                \"TRAINING\": {\n",
    "                    \"CONVERSATIONS\":\n",
    "                    \"inputs/pan-2012-training/pan12-sexual-predator-identification-training-corpus-2012-05-01.xml\",\n",
    "                    \"SEXUAL_PREDATORS\":\n",
    "                    \"inputs/pan-2012-training/pan12-sexual-predator-identification-training-corpus-predators-2012-05-01.txt\"\n",
    "                },\n",
    "                \"TESTING\": {\n",
    "                    \"CONVERSATIONS\":\n",
    "                    \"inputs/pan-2012-testing/pan12-sexual-predator-identification-test-corpus-2012-05-17.xml\",\n",
    "                    \"SEXUAL_PREDATORS\":\n",
    "                    \"inputs/pan-2012-testing/pan12-sexual-predator-identification-groundtruth-problem1.txt\",\n",
    "                    \"SUSPICIOUS_CONVERSATIONS\":\n",
    "                    \"inputs/pan-2012-testing/pan12-sexual-predator-identification-groundtruth-problem2.txt\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"MODELS\": {\n",
    "        \"BERT\": {\n",
    "            \"NAME\": \"bert-base-uncased\",\n",
    "            \"TOKENIZER\": {\n",
    "                \"MAX_LENGTH\": 128,\n",
    "                \"PADDING\": \"max_length\",\n",
    "                \"TRUNCATION\": True\n",
    "            },\n",
    "        },\n",
    "        \"32BS_24MBS_2e-05LR_3E\": \"outputs/phase_1/models/32BS_24MBS_2e-05LR_3E\",\n",
    "        \"32BS_24MBS_5e-05LR_4E\": \"outputs/phase_1/models/32BS_24MBS_5e-05LR_4E\"\n",
    "    },\n",
    "    \"PREPROCESSING\": {\n",
    "        \"RANDOMNESS\": {\n",
    "            \"SEED\": 400\n",
    "        },\n",
    "        \"MESSAGE_BATCHING\": {\n",
    "            \"SIZE\": 24\n",
    "        },\n",
    "        \"REGEXES\": {\n",
    "            \"XML_QUOTE_ESCAPES\": compile(r\"&(apos|quot);\")\n",
    "        }\n",
    "    },\n",
    "    \"INPUTS\": {\n",
    "        \"FOCUS_MODEL\": \"32BS_24MBS_5e-05LR_4E\"\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder recrear (hasta cierto punto) cada uno de los resultados propuestos, preestableceremos una semilla. Es posible que existan diferencias entre una ejecución y otra ya que como trabajaremos a nivel de GPU, muchas de las operaciones en Tensorflow son procesadas de manera asíncrona, y muchos de los valores que tratamos acá requieren sumar flotantes que sí se ven afectados cuando cambian sus órdenes. Si quisiéramos habilitar un determinismo completo, usaríamos la instrucción `tensorflow.config.experimental.enable_op_determinism()`, pero veríamos una degradación en el desempeño de las instrucciones en varios órdenes de magnitud. Para mayores detalles, revisar la [documentación oficial](https://www.tensorflow.org/versions/r2.8/api_docs/python/tf/config/experimental/enable_op_determinism) de Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import set_random_seed\n",
    "\n",
    "set_random_seed(CONSTANTS.PREPROCESSING.RANDOMNESS.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación del conjunto de entrenamiento y validación\n",
    "\n",
    "El conjunto de datos de **entrenamiento** PAN2012 tiene dos archivos de utilidad:\n",
    "\n",
    "1. `pan12-sexual-predator-identification-training-corpus-predators-2012-05-01.txt`: Enlista todos los identificadores de los autores que (se sabe) son depredadores sexuales separados por saltos de línea.\n",
    "1. `pan12-sexual-predator-identification-training-corpus-2012-05-01.xml`: Enlista tanto conversaciones normales como pervertidas en un formato de etiquetas. Cada conversación se encierra con `<conversation>` y cada mensaje por `<message>`.\n",
    "\n",
    "La cantidad de conversaciones normales versus pervertidas está altamente desequilibrada, por lo que se hará un tratamiento básico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree import cElementTree as ET\n",
    "from xml.sax.saxutils import unescape\n",
    "from re import sub\n",
    "from pandas import Series\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from transformers import DataCollatorWithPadding\n",
    "from numpy.random import default_rng\n",
    "\n",
    "\n",
    "def parse_xml_to_hf_dataset(sexual_predators_path, conversations_path):\n",
    "    dataset = {\n",
    "        \"conversation_id\": [],\n",
    "        \"conversation_label\": [],\n",
    "        \"message\": [],\n",
    "    }\n",
    "\n",
    "    with open(sexual_predators_path, \"r\") as file:\n",
    "        sexual_predators = []\n",
    "\n",
    "        for sexual_predator in file.readlines():\n",
    "            sexual_predator = sexual_predator.strip()\n",
    "            sexual_predators.append(sexual_predator)\n",
    "\n",
    "    for event, element in ET.iterparse(conversations_path,\n",
    "                                       events=(\"start\", \"end\")):\n",
    "        if event != \"end\" or element.tag != \"conversation\":\n",
    "            continue\n",
    "\n",
    "        conversation_id = element.get(\"id\").strip()\n",
    "        messages = element.findall(\"message\")\n",
    "        unescaped_messages = []\n",
    "\n",
    "        conversation_includes_sexual_predator = False\n",
    "\n",
    "        for index, message in enumerate(messages):\n",
    "            author = message.find(\"author\").text.strip()\n",
    "            message = message.find(\"text\")\n",
    "\n",
    "            if message is None:\n",
    "                continue\n",
    "\n",
    "            if message.text is None:\n",
    "                continue\n",
    "\n",
    "            if author in sexual_predators:\n",
    "                conversation_includes_sexual_predator = True\n",
    "\n",
    "            unescaped_message = sub(\n",
    "                CONSTANTS.PREPROCESSING.REGEXES.XML_QUOTE_ESCAPES, \"'\",\n",
    "                unescape(message.text.strip()))\n",
    "            unescaped_messages.append(unescaped_message)\n",
    "\n",
    "        if not unescaped_messages:\n",
    "            continue\n",
    "\n",
    "        grouped_messages = []\n",
    "\n",
    "        for index in range(0, len(unescaped_messages),\n",
    "                           CONSTANTS.PREPROCESSING.MESSAGE_BATCHING.SIZE):\n",
    "            grouped_messages.append(\"\\n\".join(\n",
    "                unescaped_messages[index:index + CONSTANTS.PREPROCESSING.\n",
    "                                   MESSAGE_BATCHING.SIZE]))\n",
    "\n",
    "        dataset[\"conversation_id\"].append(conversation_id)\n",
    "        dataset[\"conversation_label\"].append(\n",
    "            conversation_includes_sexual_predator)\n",
    "        dataset[\"message\"].append(grouped_messages)\n",
    "\n",
    "    hf_dataset = Dataset.from_dict(dataset)\n",
    "\n",
    "    return hf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recuperación del modelo\n",
    "\n",
    "Se recuperará el modelo `CONSTANTS.INPUTS.FOCUS_MODEL` entrenado durante la fase 1 y su respectivo *tokenizer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained(\n",
    "    CONSTANTS.MODELS[CONSTANTS.INPUTS.FOCUS_MODEL])\n",
    "tokenizer = AutoTokenizer.from_pretrained(CONSTANTS.MODELS.BERT.NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de los conjuntos de datos\n",
    "\n",
    "Obtendremos los *embeddings* de cada mensaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import constant\n",
    "\n",
    "\n",
    "def pooler_outputs(example, model):\n",
    "    indexes = []\n",
    "    flatten_input_ids = []\n",
    "\n",
    "    for input_ids in example[\"input_ids\"]:\n",
    "        if len(indexes) == 0:\n",
    "            indexes.append((0, len(input_ids)))\n",
    "        else:\n",
    "            indexes.append((indexes[-1][1], indexes[-1][1] + len(input_ids)))\n",
    "\n",
    "        flatten_input_ids += input_ids\n",
    "\n",
    "    tf_example = constant(flatten_input_ids)\n",
    "    pooler_output = model.bert(tf_example).pooler_output\n",
    "    reshaped_pooler_output = []\n",
    "\n",
    "    for index in indexes:\n",
    "        reshaped_pooler_output.append(pooler_output[index[0]:index[1]])\n",
    "\n",
    "    return {\"pooler_output\": reshaped_pooler_output}\n",
    "\n",
    "\n",
    "hf_training_dataset = parse_xml_to_hf_dataset(\n",
    "    CONSTANTS.DATASETS.PAN.PATHS.TRAINING.SEXUAL_PREDATORS,\n",
    "    CONSTANTS.DATASETS.PAN.PATHS.TRAINING.CONVERSATIONS)\n",
    "hf_training_dataset = hf_training_dataset.map(lambda example: tokenizer(\n",
    "    example[\"message\"],\n",
    "    max_length=CONSTANTS.MODELS.BERT.TOKENIZER.MAX_LENGTH,\n",
    "    padding=CONSTANTS.MODELS.BERT.TOKENIZER.PADDING,\n",
    "    truncation=CONSTANTS.MODELS.BERT.TOKENIZER.TRUNCATION))\n",
    "hf_training_dataset = hf_training_dataset.map(\n",
    "    lambda example: pooler_outputs(example, model),\n",
    "    batched=True,\n",
    "    batch_size=64)\n",
    "\n",
    "hf_testing_dataset = parse_xml_to_hf_dataset(\n",
    "    CONSTANTS.DATASETS.PAN.PATHS.TESTING.SEXUAL_PREDATORS,\n",
    "    CONSTANTS.DATASETS.PAN.PATHS.TESTING.CONVERSATIONS)\n",
    "hf_testing_dataset = hf_testing_dataset.map(lambda example: tokenizer(\n",
    "    example[\"message\"],\n",
    "    max_length=CONSTANTS.MODELS.BERT.TOKENIZER.MAX_LENGTH,\n",
    "    padding=CONSTANTS.MODELS.BERT.TOKENIZER.PADDING,\n",
    "    truncation=CONSTANTS.MODELS.BERT.TOKENIZER.TRUNCATION))\n",
    "hf_testing_dataset = hf_testing_dataset.map(\n",
    "    lambda example: pooler_outputs(example, model),\n",
    "    batched=True,\n",
    "    batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardaremos el conjunto anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_training_dataset.save_to_disk(\n",
    "    f\"outputs/phase_1/datasets/with_attentions/training/huggingface/{CONSTANTS.INPUTS.FOCUS_MODEL}\"\n",
    ")\n",
    "hf_testing_dataset.save_to_disk(\n",
    "    f\"outputs/phase_1/datasets/with_attentions/testing/huggingface/{CONSTANTS.INPUTS.FOCUS_MODEL}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
